{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20922a9f",
   "metadata": {},
   "source": [
    "### # Soft Prompt Tuning for ROS 2 Command Generation\n",
    "Using Qwen2.5-Coder-1.5B-Instruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d748388",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3117759",
   "metadata": {},
   "source": [
    "2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89da82f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-Coder-1.5B-Instruct\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "N_PROMPT_TOKENS = 20\n",
    "LR = 1e-4\n",
    "EPOCHS = 150\n",
    "MAX_NEW_TOKENS = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccdad42",
   "metadata": {},
   "source": [
    "3. Training Data (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cf197a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    (\n",
    "        \"Move forward 2 meters\",\n",
    "        \"ros2 topic pub /cmd_vel geometry_msgs/msg/Twist \\\"{linear: {x: 2.0}}\\\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"Turn left 90 degrees\",\n",
    "        \"ros2 service call /rotate_robot robot_msgs/srv/Rotate \\\"{angle: 1.57}\\\"\"\n",
    "    ),\n",
    "    (\n",
    "        \"Navigate to waypoint A\",\n",
    "        \"ros2 action send_goal /navigate_to_pose nav2_msgs/action/NavigateToPose \"\n",
    "        \"\\\"{pose: {header: {frame_id: 'map'}, pose: {position: {x: 5.0, y: 2.0}}}}\\\"\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f73e1e",
   "metadata": {},
   "source": [
    "4. Load Model & Tokenizer (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7390c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16 if DEVICE == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Freeze base model\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e71d0a",
   "metadata": {},
   "source": [
    "5. Soft Prompt Module (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfbb23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SoftPrompt(nn.Module):\n",
    "    def __init__(self, n_tokens, embedding_layer):\n",
    "        super().__init__()\n",
    "\n",
    "        init_prompt = embedding_layer.weight[:n_tokens].detach().clone()\n",
    "        self.prompt_embeddings = nn.Parameter(init_prompt)\n",
    "\n",
    "        print(\"Soft prompt shape:\", self.prompt_embeddings.shape)\n",
    "\n",
    "    def forward(self, batch_size):\n",
    "        return self.prompt_embeddings.unsqueeze(0).expand(batch_size, -1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044bdc6b",
   "metadata": {},
   "source": [
    "6. Initialize Soft Prompt (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990a10e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embedding_layer = model.get_input_embeddings()\n",
    "print(\"Embedding table shape:\", embedding_layer.weight.shape)\n",
    "\n",
    "soft_prompt = SoftPrompt(\n",
    "    N_PROMPT_TOKENS,\n",
    "    embedding_layer\n",
    ").to(embedding_layer.weight.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573e4dc",
   "metadata": {},
   "source": [
    "7. Loss Function (Clean Version) (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7edae5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def compute_loss(input_text, target_text):\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    target_ids = tokenizer(target_text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    batch_size = input_ids.size(0)\n",
    "\n",
    "    # Token embeddings\n",
    "    full_ids = torch.cat([input_ids, target_ids], dim=1)\n",
    "    token_embeds = model.get_input_embeddings()(full_ids)\n",
    "\n",
    "    # Soft prompt embeddings\n",
    "    prompt_embeds = soft_prompt(batch_size)\n",
    "\n",
    "    # Final embeddings\n",
    "    full_embeds = torch.cat([prompt_embeds, token_embeds], dim=1)\n",
    "\n",
    "    # Attention mask\n",
    "    attention_mask = torch.ones(\n",
    "        full_embeds.size()[:-1],\n",
    "        device=model.device,\n",
    "        dtype=torch.long\n",
    "    )\n",
    "\n",
    "    # Labels (ignore prompt + input)\n",
    "    labels = torch.cat([\n",
    "        torch.full(\n",
    "            (batch_size, N_PROMPT_TOKENS + input_ids.size(1)),\n",
    "            -100,\n",
    "            device=model.device\n",
    "        ),\n",
    "        target_ids\n",
    "    ], dim=1)\n",
    "\n",
    "    outputs = model(\n",
    "        inputs_embeds=full_embeds,\n",
    "        attention_mask=attention_mask,\n",
    "        labels=labels\n",
    "    )\n",
    "    return outputs.loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3e2a6",
   "metadata": {},
   "source": [
    "8. Training Loop (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d173310",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(soft_prompt.parameters(), lr=LR)\n",
    "\n",
    "print(\"=\" * 40)\n",
    "print(\"ðŸš€ Starting Prompt Tuning\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inp, out in train_data:\n",
    "        loss = compute_loss(inp, out)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(soft_prompt.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1:03d} | Loss: {total_loss:.4f}\")\n",
    "\n",
    "print(\"âœ¨ Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd4fa3",
   "metadata": {},
   "source": [
    "9. Save Soft Prompt (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb04cf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(soft_prompt.state_dict(), \"soft_prompt_ros2.pt\")\n",
    "print(\"âœ… Saved soft_prompt_ros2.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82ed47",
   "metadata": {},
   "source": [
    "10. Inference Function (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbcc6f9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def infer_ros2_command(human_input):\n",
    "    input_ids = tokenizer(human_input, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "    input_embeds = model.get_input_embeddings()(input_ids)\n",
    "\n",
    "    prompt_embeds = soft_prompt(1)\n",
    "    full_embeds = torch.cat([prompt_embeds, input_embeds], dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            inputs_embeds=full_embeds,\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4ef2c",
   "metadata": {},
   "source": [
    "11. Test the Model (Markdown + Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ed8cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tests = [\n",
    "    \"Move forward 9 meters\",\n",
    "    \"Turn left 90 degrees\",\n",
    "    \"Navigate to waypoint A\"\n",
    "]\n",
    "\n",
    "for t in tests:\n",
    "    print(\"Input :\", t)\n",
    "    print(\"Output:\", infer_ros2_command(t))\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
